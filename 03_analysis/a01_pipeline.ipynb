{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done...\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import pyxdf\n",
    "import mne\n",
    "from utils import *\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "print('Imports done...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Helper functions:\n",
    "def extract_eeg(stream, kick_last_ch=True):\n",
    "    \"\"\"\n",
    "    Extracts the EEG data and the EEG timestamp data from the stream and stores it into two lists.\n",
    "    :param stream: XDF stream containing the EEG data.\n",
    "    :param kick_last_ch: Boolean to kick out the brainproducts marker channel\n",
    "    :return: eeg: list containing the eeg data\n",
    "             eeg_ts: list containing the eeg timestamps.cd\n",
    "    \"\"\"\n",
    "    eeg = eeg_stream['time_series'].T\n",
    "    eeg *= 1e-6 # Convert to volts.\n",
    "    assert eeg.shape[0] == 65\n",
    "    eeg_ts = eeg_stream['time_stamps']\n",
    "\n",
    "    if kick_last_ch:\n",
    "        # Kick the last row (unused Brainproduct markers):\n",
    "        eeg = eeg[:64,:]\n",
    "\n",
    "    return eeg, eeg_ts\n",
    "\n",
    "\n",
    "def extract_eeg_infos(stream):\n",
    "    # Extract all infos from the EEG stream:\n",
    "    recording_device = stream['info']['name'][0]\n",
    "    sampling_rate = float(stream['info']['nominal_srate'][0])\n",
    "    effective_sample_frequency = float(stream['info']['effective_srate'])\n",
    "\n",
    "    # Extract channel names:\n",
    "    names = [stream['info']['desc'][0]['channels'][0]['channel'][i]['label'][0] for i in range(64)]\n",
    "    # chn_names.append('Markers')\n",
    "    labels = ['eeg' for i in range(64)]\n",
    "    labels[16] = 'eog'\n",
    "    labels[21] = 'eog'\n",
    "    labels[40] = 'eog'\n",
    "    # chn_labels.append('misc')\n",
    "\n",
    "    return sampling_rate, names, labels, effective_sample_frequency\n",
    "\n",
    "\n",
    "def extract_annotations(marker_stream, first_samp):\n",
    "    \"\"\"\n",
    "    Function to extract the triggers of the marker stream in order to prepare for the annotations.\n",
    "    :param marker_stream: xdf stream containing the markers and time_stamps\n",
    "    :param first_samp: First EEG sample, serves for aligning the markers\n",
    "    :return: triggers: Dict containing the extracted triggers.\n",
    "    \"\"\"\n",
    "    triggers = {'onsets': [], 'duration': [], 'description': []}\n",
    "\n",
    "    # Extract the markers:\n",
    "    markers = marker_stream['time_series']\n",
    "\n",
    "    # Extract the timestamp of the markers an correct them to zero\n",
    "    markers_ts = marker_stream['time_stamps'] - first_samp\n",
    "\n",
    "    # Read every trigger in the stream\n",
    "    for idx, marker_data in enumerate(markers):\n",
    "        # extract triggers information\n",
    "        triggers['onsets'].append(markers_ts[idx])\n",
    "        triggers['duration'].append(int(0))\n",
    "        # print(marker_data[0])\n",
    "        triggers['description'].append(marker_data[0])\n",
    "\n",
    "    return triggers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "path = 'C:/Users/tumfart/Code/github/master-thesis/data/'\n",
    "subjects = ['A01', 'A02'] #, 'A03', 'A04', 'A05', 'A06', 'A07' , 'A08', 'A09', 'A10']\n",
    "# = 'A03'\n",
    "paradigm = 'paradigm' # 'eye', 'paradigm'\n",
    "plot = False\n",
    "mne.set_log_level('WARNING')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read xdf-files for specified subject"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Create path list for each subject:\n",
    "paths = [str(path + subject + '/' + paradigm) for subject in subjects]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting subject A01...\n",
      "#############################################\n",
      "Extracting subject A02...\n",
      "#############################################\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each subject and extract the streams\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Extracting subject {subject}...')\n",
    "    file_names = [f for f in listdir(path)]\n",
    "\n",
    "    for file_name in file_names:\n",
    "        print(f'####', end='#')\n",
    "        file = path + '/' + file_name\n",
    "\n",
    "        # Read the raw stream:\n",
    "        streams, header = pyxdf.load_xdf(file)\n",
    "\n",
    "        # Split the streams:\n",
    "        eeg_stream, marker_stream = split_streams(streams)\n",
    "\n",
    "        # Get the eeg data:\n",
    "        eeg, eeg_ts = extract_eeg(eeg_stream, kick_last_ch=True)\n",
    "        #max_eeg_ts.append(eeg_ts.max())\n",
    "\n",
    "        # Extract all infos from the EEG stream:\n",
    "        fs, ch_names, ch_labels, eff_fs = extract_eeg_infos(eeg_stream)\n",
    "\n",
    "        # Extract the triggers from the marker stream:\n",
    "        triggers = extract_annotations(marker_stream, first_samp=eeg_ts[0])\n",
    "\n",
    "        # Define MNE annotations\n",
    "        annotations = mne.Annotations(triggers['onsets'], triggers['duration'], triggers['description'], orig_time=None)\n",
    "\n",
    "        # Create mne info:\n",
    "        # TODO: Check what info can be added to the stream:\n",
    "        info = mne.create_info(ch_names, fs, ch_labels)\n",
    "\n",
    "        # Create the raw array and add info, montage and annotations:\n",
    "        raw = mne.io.RawArray(eeg, info, first_samp=eeg_ts[0])\n",
    "        raw.set_montage('standard_1005')\n",
    "        raw.set_annotations(annotations)\n",
    "\n",
    "        if plot:\n",
    "            raw.plot(duration=60, proj=False, n_channels=len(raw.ch_names),\n",
    "                     remove_dc=False, title='Raw')\n",
    "\n",
    "    print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####\n",
      "Finished reading, found 1 EEG streams and 1 marker streams...\n"
     ]
    }
   ],
   "source": [
    "# List files in folder:\n",
    "files = [f for f in listdir(path)]\n",
    "\n",
    "eeg_streams = []\n",
    "marker_streams = []\n",
    "# Load all recorded EEG files for one subjectc\n",
    "files = [files[0]]\n",
    "for file in files:\n",
    "    file_name = path + '/' + file\n",
    "    print(f'####', end='#')\n",
    "\n",
    "    # Read streams\n",
    "    streams, header = pyxdf.load_xdf(file_name)\n",
    "\n",
    "    # Split the streams:\n",
    "    eeg_stream, marker_stream = split_streams(streams)\n",
    "\n",
    "    eeg_streams.append(eeg_stream)\n",
    "    marker_streams.append(marker_stream)\n",
    "\n",
    "\n",
    "print()\n",
    "print(f'Finished reading, found {len(eeg_streams)} EEG streams and {len(marker_streams)} marker streams...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####\n",
      "Extracted EEG data, EEG infos...\n"
     ]
    }
   ],
   "source": [
    "differences = [0]\n",
    "max_eeg_ts = []\n",
    "for i, (eeg_stream, m_stream) in enumerate(zip(eeg_streams, marker_streams)):\n",
    "    # Get the eeg data:\n",
    "    eeg, eeg_ts = extract_eeg(eeg_stream)\n",
    "    max_eeg_ts.append(eeg_ts.max())\n",
    "\n",
    "    # Kick the last row (unused Brainproduct markers):\n",
    "    eeg = eeg[:64,:]\n",
    "\n",
    "    # Extract all infos from the EEG stream:\n",
    "    fs, ch_names, ch_labels, eff_fs = extract_eeg_infos(eeg_stream)\n",
    "\n",
    "    # Extract the markers and timestamps:\n",
    "    # markers = m_stream['time_series']\n",
    "    # markers_ts = m_stream['time_stamps']\n",
    "    #\n",
    "    # # Convert list of list of strings to list of strings:\n",
    "    # markers = [''.join(element) for element in markers]\n",
    "\n",
    "    # # Make Nan array with len(eeg)\n",
    "    # aligned_markers = np.empty(eeg_ts.shape, dtype='<U5')\n",
    "    #\n",
    "    # # Place markers string at the align array where first time markers_ts <= eeg_ts:\n",
    "    # for k, marker in enumerate(markers):\n",
    "    #     ts = markers_ts[k]\n",
    "    #     idx = np.where(ts <= eeg_ts)[0][0]\n",
    "    #     aligned_markers[idx] = marker\n",
    "\n",
    "    if i == 0:\n",
    "        global_eeg = eeg\n",
    "        first_ts = eeg_ts[0]\n",
    "        # global_markers = aligned_markers\n",
    "    else:\n",
    "        global_eeg = np.concatenate((global_eeg, eeg), axis=1)\n",
    "        # global_markers = np.concatenate((global_markers, aligned_markers))\n",
    "        differences.append(eeg_ts[0]-last_ts)\n",
    "\n",
    "    last_ts = eeg_ts[-1]\n",
    "    print(f'####', end='#')\n",
    "\n",
    "cum_diff = np.cumsum(differences)\n",
    "eeg = global_eeg\n",
    "# markers = global_markers\n",
    "print()\n",
    "print('Extracted EEG data, EEG infos...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# annotation generation from:\n",
    "# https://github.com/WriessneggerLab/EEG-preprocessing/blob/eeg/src/EEGAnalysis.py\n",
    "# generation of the events according to the definition\n",
    "triggers = {'onsets': [], 'duration': [], 'description': []}\n",
    "global_markers_ts = []\n",
    "for i, m_stream in enumerate(marker_streams):\n",
    "    # Extract the markers and timestamps:\n",
    "    markers = m_stream['time_series']\n",
    "    markers_ts = m_stream['time_stamps'] - float(m_stream['info']['created_at'][0])# - cum_diff[i]\n",
    "\n",
    "\n",
    "    global_markers_ts += list(markers_ts)\n",
    "    # read every trigger in the stream\n",
    "    for idx, marker_data in enumerate(markers):\n",
    "        # extract triggers information\n",
    "        triggers['onsets'].append(markers_ts[idx])\n",
    "        triggers['duration'].append(int(0))\n",
    "        # print(marker_data[0])\n",
    "        triggers['description'].append(marker_data[0])\n",
    "\n",
    "# define MNE annotations\n",
    "annotations = mne.Annotations(triggers['onsets'], triggers['duration'], triggers['description'], orig_time=None) #, orig_time=np.array(global_markers_ts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mrks_list = list(markers_ts)\n",
    "a = []\n",
    "a += mrks_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Put extracted data into mne structure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=86908\n",
      "    Range : 612437 ... 699344 =   3062.185 ...  3496.720 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tumfart\\AppData\\Local\\Temp\\ipykernel_2368\\2651053216.py:7: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    }
   ],
   "source": [
    "# TODO: align annotations\n",
    "\n",
    "info = mne.create_info(ch_names, fs, ch_labels)\n",
    "\n",
    "raw = mne.io.RawArray(eeg, info, first_samp=first_ts)\n",
    "raw.set_montage('standard_1005')\n",
    "raw.set_annotations(annotations)\n",
    "\n",
    "if plot:\n",
    "    raw.plot(duration=60, proj=False, n_channels=len(raw.ch_names),\n",
    "             remove_dc=False, title='Raw')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mnelab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmnelab\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mxdf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m read_raw_xdf\n\u001B[0;32m      3\u001B[0m raw \u001B[38;5;241m=\u001B[39m read_raw_xdf(path\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msub-A03_ses-S001_task-paradigm_run-001_eeg.xdf\u001B[39m\u001B[38;5;124m'\u001B[39m, stream_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'mnelab'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter with HP at 0.4Hz and BS at 50 Hz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_highpass = raw.copy().filter(l_freq=0.4, h_freq=None, picks=['eeg'], method='iir')\n",
    "if plot:\n",
    "    raw_highpass.plot(duration=60, proj=False, n_channels=len(raw.ch_names),\n",
    "                      remove_dc=False, title='Highpass filtered')\n",
    "    plot_spectrum(raw_highpass)\n",
    "\n",
    "raw_notch = raw_highpass.copy().notch_filter(freqs=[50], picks=['eeg'])\n",
    "if plot:\n",
    "    raw_notch.plot(duration=60, proj=False, n_channels=len(raw.ch_names), remove_dc=False, title='Notch filtered')\n",
    "    plot_spectrum(raw_notch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interpolate bad channels:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: check function --> need to mark them first\n",
    "raw_interp = raw_notch.copy().interpolate_bads(reset_bads=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correct eye artifacts:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CAR:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_avg_ref = raw_interp.copy().set_eeg_reference(ref_channels='average')\n",
    "if plot:\n",
    "    raw_avg_ref.plot(duration=60, proj=False, n_channels=len(raw.ch_names), remove_dc=False, title='CAR Referenced')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HEAR model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LP at 3.0Hz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_lp = raw_avg_ref.copy().filter(l_freq=None, h_freq=3.0, picks=['eeg'], method='iir')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract epochs before resampling (otherwise markers may get lost) and reject bad trials:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events = mne.find_events(raw_lp, stim_channel='Markers')\n",
    "\n",
    "epochs = mne.Epochs(raw_lp, events, event_id=classes_map, tmin=1, tmax=6, preload=True, baseline=None, reject=dict(eeg=100e-6)) #, baseline=(1,2))\n",
    "\n",
    "print(epochs)\n",
    "\n",
    "if plot:\n",
    "    epochs.plot(n_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resample to 10 Hz:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs_resampled = epochs.copy().resample(10)\n",
    "print('Preprocessing finished.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing cue-aligned (better according to Reinmar paper)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Distance decoding:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events = mne.find_events(raw_lp, stim_channel='Markers')\n",
    "event_dict = {'short': 1, 'long': 2, 'short': 1, 'long': 2, 'short':1, 'long':2, 'short':1, 'long':2}\n",
    "\n",
    "epochs_long_short = mne.Epochs(raw_lp, events, event_id=event_dict, tmin=1, tmax=6, preload=True, baseline=None, reject=dict(eeg=100e-6))\n",
    "\n",
    "\n",
    "\n",
    "short = epochs_long_short['short'].average()\n",
    "\n",
    "long = epochs_long_short['long'].average()\n",
    "\n",
    "#evokeds = dict(short=short, long=long)\n",
    "#mne.viz.plot_compare_evokeds(evokeds, picks='POz')\n",
    "\n",
    "evokeds2 = dict(short=list(epochs_long_short['short'].iter_evoked()),\n",
    "                long=list(epochs_long_short['long'].iter_evoked()))\n",
    "mne.viz.plot_compare_evokeds(evokeds2, combine='mean', picks=['Cz', 'C1', 'C2', 'FCz', 'CPz'], show_sensors='upper right')\n",
    "plt.savefig('distance_grand_averages.pdf')\n",
    "\n",
    "#['Pz', 'POz', 'PO3', 'PO4', 'P2', 'P1', 'P2', 'Oz', 'O1', 'O2']\n",
    "\n",
    "epochs_long_short = epochs_long_short.copy().resample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i,epoch in enumerate(epochs_long_short):\n",
    "    #print(epoch.shape)\n",
    "    # Deleting EOG channels:\n",
    "    epoch = np.delete(epoch, 40, 0)\n",
    "    epoch = np.delete(epoch, 21, 0)\n",
    "    epoch = np.delete(epoch, 16, 0)\n",
    "    X.append(epoch[:61,:])\n",
    "    y.append(list(epochs_long_short[i].event_id.values())[0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(y)\n",
    "\n",
    "for i,label in enumerate(y):\n",
    "    if label % 2 == 0:\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n",
    "# Split training and test set:\n",
    "\n",
    "clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "acc = []\n",
    "cv_scores = []\n",
    "for idx in range(len(X[0,0])):\n",
    "    x = X[:,:,idx]\n",
    "    # Reshape X to 2d array:\n",
    "    #nsamples, nx, ny = x.shape\n",
    "    #x = x.reshape((nsamples,nx*ny))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc.append(clf.score(X_test, y_test))\n",
    "\n",
    "    scores = cross_val_score(clf, x, y, cv=100)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "    if idx % 10 == 0:\n",
    "        print(idx)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "t = np.arange(len(acc))\n",
    "t = t/10\n",
    "#plt.plot(t, acc)\n",
    "\n",
    "plt.plot(t, cv_scores)\n",
    "\n",
    "window = 7\n",
    "\n",
    "ma = np.convolve(cv_scores, np.ones(window), 'valid') / window\n",
    "\n",
    "plt.plot(t[:-window+1], ma)\n",
    "plt.plot([2,2], [min(cv_scores), max(cv_scores)])\n",
    "plt.title('Single sample approach, 180-fold CV')\n",
    "plt.savefig('distance_acc_single.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 point LDA\n",
    "X = []\n",
    "y = []\n",
    "for i,epoch in enumerate(epochs_long_short):\n",
    "    #print(epoch.shape)\n",
    "    # Deleting Marker channel:\n",
    "    # Deleting EOG channels:\n",
    "    epoch = np.delete(epoch, 40, 0)\n",
    "    epoch = np.delete(epoch, 21, 0)\n",
    "    epoch = np.delete(epoch, 16, 0)\n",
    "    X.append(epoch[:61,:])\n",
    "    y.append(list(epochs_long_short[i].event_id.values())[0])\n",
    "\n",
    "for i,label in enumerate(y):\n",
    "    if label % 2 == 0:\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "# Split training and test set:\n",
    "\n",
    "clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "acc = []\n",
    "cv_scores = []\n",
    "for idx in range(len(X[0,0])-5):\n",
    "    x = X[:,:,idx:idx+5]\n",
    "    if idx % 10 == 0:\n",
    "        print(idx)\n",
    "        print(x.shape)\n",
    "    # Reshape X to 2d array:\n",
    "    nsamples, nx, ny = x.shape\n",
    "    x = x.reshape((nsamples,nx*ny))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc.append(clf.score(X_test, y_test))\n",
    "\n",
    "    scores = cross_val_score(clf, x, y, cv=100)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "print('Done')\n",
    "#print(acc)\n",
    "\n",
    "t = np.arange(len(acc))\n",
    "t = t/10 + 5/10\n",
    "#plt.plot(t, acc)\n",
    "\n",
    "plt.plot(t, cv_scores)\n",
    "\n",
    "window = 7\n",
    "\n",
    "ma = np.convolve(cv_scores, np.ones(window), 'valid') / window\n",
    "\n",
    "plt.plot(t[window-1:], ma)\n",
    "plt.plot([2,2], [min(cv_scores), max(cv_scores)])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Accuracy (a.u.)')\n",
    "plt.title('Windowed approach accuracies, distance 180-fold CV')\n",
    "plt.savefig('distance_acc_5point.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}