{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import exists\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyxdf\n",
    "import mne\n",
    "from utils import *\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime, timezone\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "\n",
    "print('Imports done...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data_path = 'C:/Users/tumfart/Code/github/master-thesis/data/'\n",
    "data_path = 'C:/Users/peter/Google Drive/measurements/eeg/'\n",
    "subjects = ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07' , 'A08', 'A09', 'A10']\n",
    "# = 'A03'\n",
    "paradigm = 'paradigm' # 'eye', 'paradigm'\n",
    "plot = False\n",
    "mne.set_log_level('WARNING')\n",
    "# Create path list for each subject:\n",
    "paths = [str(data_path + subject + '/' + paradigm) for subject in subjects]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read all .npy coefficients:\n",
    "start = time.time()\n",
    "A = []\n",
    "for subject, path in zip(subjects, paths):\n",
    "    file_names = [f for f in listdir(path) if 'regr_coeff.npy' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    A.append(np.load(file))\n",
    "\n",
    "n_chan, n_coeff, n_ts = A[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate mean for each channel and for each timestamp:\n",
    "n_chan, n_coeff, n_ts = A[0].shape\n",
    "means = np.empty((n_chan, n_coeff, n_ts))\n",
    "uppers = np.empty((n_chan, n_coeff, n_ts))\n",
    "lowers = np.empty((n_chan, n_coeff, n_ts))\n",
    "means[:], uppers[:], lowers[:] = np.nan, np.nan, np.nan\n",
    "\n",
    "stat = np.empty((n_chan, n_ts))\n",
    "p_val = np.empty((n_chan, n_ts))\n",
    "stat[:], p_val[:] = np.nan, np.nan\n",
    "\n",
    "confidence = 0.95\n",
    "start = time.time()\n",
    "for ts in range(n_ts):\n",
    "    for chan in range(n_chan):\n",
    "        print(f'{ts+1}/{n_ts}, {chan+1}/{n_chan}', end='\\r')\n",
    "        for coeff in range(n_coeff):\n",
    "            a = [A[i][chan, coeff, ts] for i in range(len(subjects))] # Get list of all subject for a specific channel, coefficient and timestamp\n",
    "\n",
    "            # Calculate mean:\n",
    "            # Bootstrapping for confidence interval:\n",
    "            values = [np.random.choice(a, size=len(a),replace=True).mean() for i in range(500)]\n",
    "            means[chan,coeff,ts] = np.array(values).mean()\n",
    "            lowers[chan,coeff,ts], uppers[chan,coeff,ts] = np.percentile(values,[100*(1-confidence)/2,100*(1-(1-confidence)/2)])\n",
    "\n",
    "        rvs1 = [A[i][chan, 1, ts] for i in range(len(subjects))]\n",
    "        rvs2 = [A[i][chan, 2, ts] for i in range(len(subjects))]\n",
    "        # Calculate t-test for coeff[1] vs coeff[2] (distance vs. direction):\n",
    "        stat[chan,ts], p_val[chan, ts] = stats.ttest_ind(rvs1, rvs2)\n",
    "\n",
    "print(f'Bootstrapping, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save bootstrapping matrices:\n",
    "np.save('regr_coeff_global_means.npy', means)    # .npy extension is added if not given\n",
    "np.save('regr_coeff_global_lowers.npy', lowers)\n",
    "np.save('regr_coeff_global_uppers.npy', uppers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save t-test matrices:\n",
    "np.save('regr_coeff_stats.npy', stat)\n",
    "np.save('regr_coeff_pval.npy', p_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "means = np.load('regr_coeff_global_means.npy')\n",
    "lowers = np.load('regr_coeff_global_lowers.npy')\n",
    "uppers = np.load('regr_coeff_global_uppers.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stat = np.load('regr_coeff_stats.npy')\n",
    "p_val = np.load('regr_coeff_pval.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate binary matrix for a distinct p-val:\n",
    "p_crit = 0.05\n",
    "bin_p_val = np.empty((n_chan,n_ts))\n",
    "bin_p_val[:] = False\n",
    "bin_p_val[np.where(p_val < p_crit)] = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_names = [f for f in listdir(paths[0]) if 'epo.fif' in f]\n",
    "\n",
    "# Load file\n",
    "file_name = file_names[0]\n",
    "file = paths[0] + '/' + file_name\n",
    "epochs = mne.read_epochs(file, preload=True)\n",
    "names = epochs.ch_names\n",
    "\n",
    "mapping = {'Fp1': (0,3), 'Fp2': (0,5), 'AF7': (1,0), 'AF3': (1,2), 'AF4': (1,6), 'AF8': (1,8),\n",
    "           'F7': (2,0), 'F5': (2,1), 'F3': (2,2), 'F1': (2,3), 'Fz': (2,4), 'F2': (2,5), 'F4': (2,6), 'F6': (2,7), 'F8': (2,8),\n",
    "           'FT7': (3,0), 'FC5': (3,1), 'FC3': (3,2), 'FC1': (3,3), 'FCz': (3,4), 'FC2': (3,5), 'FC4': (3,6), 'FC6': (3,7), 'FT8': (3,8),\n",
    "           'T7': (4,0), 'C5': (4,1), 'C3': (4,2), 'C1': (4,3), 'Cz': (4,4), 'C2': (4,5), 'C4': (4,6), 'C6': (4,7), 'T8': (4,8),\n",
    "           'TP7': (5,0), 'CP5': (5,1), 'CP3': (5,2), 'CP1': (5,3), 'CPz': (5,4), 'CP2': (5,5), 'CP4': (5,6), 'CP6': (5,7), 'TP8': (5,8),\n",
    "           'P7': (6,0), 'P5': (6,1), 'P3': (6,2), 'P1': (6,3), 'Pz': (6,4), 'P2': (6,5), 'P4': (6,6), 'P6': (6,7), 'P8': (6,8),\n",
    "           'PO7': (7,0), 'PO3': (7,2), 'POz': (7,4), 'PO4': (7,6), 'PO8': (7,8),\n",
    "           'PO9': (8,1), 'O1': (8,3), 'Oz': (8,4), 'O2': (8,5), 'PO10': (8,7)\n",
    "           }\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timepoints = np.arange(n_ts)\n",
    "fig, axs = plt.subplots(9, 9)\n",
    "# axs[0, 0].plot(x, y)+\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.suptitle(f'Regression coefficients')\n",
    "for chan in range(n_chan):\n",
    "    x,y = mapping[names[chan]]\n",
    "    for coeff in range(1,3):\n",
    "        axs[x, y].plot(means[chan,coeff,:])\n",
    "        axs[x, y].fill_between(timepoints, lowers[chan,coeff,:], uppers[chan,coeff,:], alpha=0.1)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('regr_topo_chans.svg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax.imshow(bin_p_val) #, cmap='Blues')\n",
    "# ax.colorbar()\n",
    "ax.yaxis.set_ticks([i for i in range(len(names))])\n",
    "ax.set_yticklabels(names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read all .npy coefficients:\n",
    "start = time.time()\n",
    "A = []\n",
    "for subject, path in zip(subjects, paths):\n",
    "    file_names = [f for f in listdir(path) if 'regr_coeff_cue_aligned.npy' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    A.append(np.load(file))\n",
    "\n",
    "n_chan, n_coeff, n_ts = A[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate mean for each channel and for each timestamp:\n",
    "n_chan, n_coeff, n_ts = A[0].shape\n",
    "means = np.empty((n_chan, n_coeff, n_ts))\n",
    "uppers = np.empty((n_chan, n_coeff, n_ts))\n",
    "lowers = np.empty((n_chan, n_coeff, n_ts))\n",
    "means[:], uppers[:], lowers[:] = np.nan, np.nan, np.nan\n",
    "\n",
    "stat = np.empty((n_chan, n_ts))\n",
    "p_val = np.empty((n_chan, n_ts))\n",
    "stat[:], p_val[:] = np.nan, np.nan\n",
    "\n",
    "confidence = 0.95\n",
    "start = time.time()\n",
    "for ts in range(n_ts):\n",
    "    for chan in range(n_chan):\n",
    "        print(f'{ts+1}/{n_ts}, {chan+1}/{n_chan}', end='\\r')\n",
    "        for coeff in range(n_coeff):\n",
    "            a = [A[i][chan, coeff, ts] for i in range(len(subjects))] # Get list of all subject for a specific channel, coefficient and timestamp\n",
    "\n",
    "            # Calculate mean:\n",
    "            # Bootstrapping for confidence interval:\n",
    "            values = [np.random.choice(a, size=len(a),replace=True).mean() for i in range(500)]\n",
    "            means[chan,coeff,ts] = np.array(values).mean()\n",
    "            lowers[chan,coeff,ts], uppers[chan,coeff,ts] = np.percentile(values,[100*(1-confidence)/2,100*(1-(1-confidence)/2)])\n",
    "\n",
    "        rvs1 = [A[i][chan, 1, ts] for i in range(len(subjects))]\n",
    "        rvs2 = [A[i][chan, 2, ts] for i in range(len(subjects))]\n",
    "        # Calculate t-test for coeff[1] vs coeff[2] (distance vs. direction):\n",
    "        stat[chan,ts], p_val[chan, ts] = stats.ttest_ind(rvs1, rvs2)\n",
    "\n",
    "print(f'Bootstrapping, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save bootstrapping matrices:\n",
    "np.save('regr_coeff_cue_aligned_global_means.npy', means)    # .npy extension is added if not given\n",
    "np.save('regr_coeff_cue_aligned_global_lowers.npy', lowers)\n",
    "np.save('regr_coeff_cue_aligned_global_uppers.npy', uppers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save t-test matrices:\n",
    "np.save('regr_coeff_stats_cue_aligned.npy', stat)\n",
    "np.save('regr_coeff_pval_cue_aligned.npy', p_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate binary matrix for a distinct p-val:\n",
    "p_crit = 0.05\n",
    "bin_p_val = np.empty((n_chan,n_ts))\n",
    "bin_p_val[:] = False\n",
    "bin_p_val[np.where(p_val < p_crit)] = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_names = [f for f in listdir(paths[0]) if 'epo.fif' in f]\n",
    "\n",
    "# Load file\n",
    "file_name = file_names[0]\n",
    "file = paths[0] + '/' + file_name\n",
    "epochs = mne.read_epochs(file, preload=True)\n",
    "names = epochs.ch_names\n",
    "\n",
    "mapping = {'Fp1': (0,3), 'Fp2': (0,5), 'AF7': (1,0), 'AF3': (1,2), 'AF4': (1,6), 'AF8': (1,8),\n",
    "           'F7': (2,0), 'F5': (2,1), 'F3': (2,2), 'F1': (2,3), 'Fz': (2,4), 'F2': (2,5), 'F4': (2,6), 'F6': (2,7), 'F8': (2,8),\n",
    "           'FT7': (3,0), 'FC5': (3,1), 'FC3': (3,2), 'FC1': (3,3), 'FCz': (3,4), 'FC2': (3,5), 'FC4': (3,6), 'FC6': (3,7), 'FT8': (3,8),\n",
    "           'T7': (4,0), 'C5': (4,1), 'C3': (4,2), 'C1': (4,3), 'Cz': (4,4), 'C2': (4,5), 'C4': (4,6), 'C6': (4,7), 'T8': (4,8),\n",
    "           'TP7': (5,0), 'CP5': (5,1), 'CP3': (5,2), 'CP1': (5,3), 'CPz': (5,4), 'CP2': (5,5), 'CP4': (5,6), 'CP6': (5,7), 'TP8': (5,8),\n",
    "           'P7': (6,0), 'P5': (6,1), 'P3': (6,2), 'P1': (6,3), 'Pz': (6,4), 'P2': (6,5), 'P4': (6,6), 'P6': (6,7), 'P8': (6,8),\n",
    "           'PO7': (7,0), 'PO3': (7,2), 'POz': (7,4), 'PO4': (7,6), 'PO8': (7,8),\n",
    "           'PO9': (8,1), 'O1': (8,3), 'Oz': (8,4), 'O2': (8,5), 'PO10': (8,7)\n",
    "           }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timepoints = np.arange(n_ts)\n",
    "fig, axs = plt.subplots(9, 9)\n",
    "# axs[0, 0].plot(x, y)+\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.suptitle(f'Regression coefficients')\n",
    "for chan in range(n_chan):\n",
    "    x,y = mapping[names[chan]]\n",
    "    for coeff in range(1,3):\n",
    "        axs[x, y].plot(means[chan,coeff,:])\n",
    "        axs[x, y].fill_between(timepoints, lowers[chan,coeff,:], uppers[chan,coeff,:], alpha=0.1)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('regr_topo_chans_cue_aligned.svg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax.imshow(bin_p_val) #, cmap='Blues')\n",
    "# ax.colorbar()\n",
    "ax.yaxis.set_ticks([i for i in range(len(names))])\n",
    "ax.set_yticklabels(names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}