{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import exists\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyxdf\n",
    "import mne\n",
    "from utils import *\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime, timezone\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "\n",
    "print('Imports done...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/tumfart/Code/github/master-thesis/data/'\n",
    "#data_path = 'C:/Users/peter/Google Drive/measurements/eeg/'\n",
    "subjects = ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07' , 'A08', 'A09', 'A10']\n",
    "# = 'A03'\n",
    "paradigm = 'paradigm' # 'eye', 'paradigm'\n",
    "plot = False\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "trial_type_markers = ['LTR-s', 'LTR-l','RTL-s', 'RTL-l', 'TTB-s', 'TTB-l', 'BTT-s', 'BTT-l']\n",
    "\n",
    "# Create path list for each subject:\n",
    "paths = [str(data_path + subject + '/' + paradigm) for subject in subjects]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 2-class classification:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Cue-based distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mne.set_log_level('INFO')\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'cue aligned 2 class long v short'\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Reading last fif file for subject {subject}', end=' ')\n",
    "    file_names = [f for f in listdir(path) if '_bad_annotations_raw.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    raw = load_raw_file(dirpath=path, file=file_names[0])\n",
    "\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Select subset of event_dict with following markers:\n",
    "\n",
    "    markers_of_interest = ['LTR-s', 'LTR-l','RTL-s', 'RTL-l', 'TTB-s', 'TTB-l', 'BTT-s', 'BTT-l']\n",
    "\n",
    "    event_dict_of_interest = get_subset_of_dict(event_dict, markers_of_interest)\n",
    "\n",
    "    epochs = mne.Epochs(raw, events_from_annot, event_id=event_dict_of_interest, tmin=0.0, tmax=7.0, baseline=None, reject_by_annotation=True, preload=True, picks=['eeg'], reject=dict(eeg=200e-6 ))\n",
    "\n",
    "    # Downsample to 10 Hz:\n",
    "    epochs = epochs.copy().resample(10)\n",
    "\n",
    "    # Save epochs:\n",
    "    store_name = path + '/' + subject + '_' + paradigm + '_epo.fif'\n",
    "    epochs.save(store_name, overwrite=True)\n",
    "\n",
    "    print()\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.1. Single timepoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying for subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    longs = [m for m in markers_of_interest if '-l' in m]\n",
    "    shorts = [m for m in markers_of_interest if '-s' in m]\n",
    "    epochs_long = epochs[longs]\n",
    "    epochs_short = epochs[shorts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_long.get_data(), epochs_short.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_long)), np.ones(len(epochs_short))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2]\n",
    "    for tp in range(X.shape[2]):\n",
    "        x = X[:,:,tp]\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': bool(False), 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "row_to_add = {'Timepoint': (np.arange(0, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [False]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.2. Windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 timestamps classifier:\n",
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    longs = [m for m in markers_of_interest if '-l' in m]\n",
    "    shorts = [m for m in markers_of_interest if '-s' in m]\n",
    "    epochs_long = epochs[longs]\n",
    "    epochs_short = epochs[shorts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_long.get_data(), epochs_short.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_long)), np.ones(len(epochs_short))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2] - 5\n",
    "    for tp in range(5,X.shape[2]):\n",
    "        x = X[:,:,tp-5:tp+1]\n",
    "        x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': True, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(5, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [True]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Movment-onset-based distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mne.set_log_level('INFO')\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'movement onset aligned 2 class long v short'\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}', end=' ')\n",
    "    file_names = [f for f in listdir(path) if '_bad_annotations_raw.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    raw = load_raw_file(dirpath=path, file=file_names[0])\n",
    "\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Select subset of event_dict with following markers:\n",
    "\n",
    "    # Looking at indication release (movement onset):\n",
    "    trial_type = trial_type_markers\n",
    "    period = ['i'] # 'i', 'c' .. indication, cue\n",
    "    position = ['l', 'r', 't', 'b', 'c']\n",
    "    state = ['1'] # 0,1 .. touch/release\n",
    "    markers_of_interest = generate_markers_of_interest(trial_type, period, position, state)\n",
    "\n",
    "    event_dict_of_interest = get_subset_of_dict(event_dict, markers_of_interest)\n",
    "\n",
    "    epochs = mne.Epochs(raw, events_from_annot, event_id=event_dict_of_interest, tmin=-2.0, tmax=3.5, baseline=None, reject_by_annotation=True, preload=True, picks=['eeg'], reject=dict(eeg=200e-6 ))\n",
    "\n",
    "    # Downsample to 10 Hz:\n",
    "    epochs = epochs.copy().resample(10)\n",
    "\n",
    "    # Save epochs:\n",
    "    store_name = path + '/' + subject + '_' + paradigm + '_epo.fif'\n",
    "    epochs.save(store_name, overwrite=True)\n",
    "\n",
    "    print()\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.1. Single timepoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifiying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    longs = [m for m in markers_of_interest if '-l' in m]\n",
    "    shorts = [m for m in markers_of_interest if '-s' in m]\n",
    "    epochs_long = epochs[longs]\n",
    "    epochs_short = epochs[shorts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_long.get_data(), epochs_short.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_long)), np.ones(len(epochs_short))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2]\n",
    "    for tp in range(X.shape[2]):\n",
    "        x = X[:,:,tp]\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': False, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "row_to_add = {'Timepoint': (np.arange(0, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [False]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.1. Windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 timestamps classifier:\n",
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    longs = [m for m in markers_of_interest if '-l' in m]\n",
    "    shorts = [m for m in markers_of_interest if '-s' in m]\n",
    "    epochs_long = epochs[longs]\n",
    "    epochs_short = epochs[shorts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_long.get_data(), epochs_short.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_long)), np.ones(len(epochs_short))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2] - 5\n",
    "    for tp in range(5,X.shape[2]):\n",
    "        x = X[:,:,tp-5:tp+1]\n",
    "        x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': True, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(5, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [True]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 4-class classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1. Cue-based direction (all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mne.set_log_level('INFO')\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'cue aligned 4 class direction (all)'\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Reading last fif file for subject {subject}', end=' ')\n",
    "    file_names = [f for f in listdir(path) if '_bad_annotations_raw.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    raw = load_raw_file(dirpath=path, file=file_names[0])\n",
    "\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Select subset of event_dict with following markers:\n",
    "\n",
    "    markers_of_interest = ['LTR-s', 'LTR-l','RTL-s', 'RTL-l', 'TTB-s', 'TTB-l', 'BTT-s', 'BTT-l']\n",
    "\n",
    "    event_dict_of_interest = get_subset_of_dict(event_dict, markers_of_interest)\n",
    "\n",
    "    epochs = mne.Epochs(raw, events_from_annot, event_id=event_dict_of_interest, tmin=0.0, tmax=7.0, baseline=None, reject_by_annotation=True, preload=True, picks=['eeg'], reject=dict(eeg=200e-6 ))\n",
    "\n",
    "    # Downsample to 10 Hz:\n",
    "    epochs = epochs.copy().resample(10)\n",
    "\n",
    "    # Save epochs:\n",
    "    store_name = path + '/' + subject + '_' + paradigm + '_epo.fif'\n",
    "    epochs.save(store_name, overwrite=True)\n",
    "\n",
    "    print()\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1. Single timepoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'cue aligned 4 class direction (all)'\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BT' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TT' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RT' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LT' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2]\n",
    "    for tp in range(X.shape[2]):\n",
    "        x = X[:,:,tp]\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': False, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(0, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [False]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2. Windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 timestamps classifier:\n",
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying for subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BT' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TT' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RT' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LT' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2] - 5\n",
    "    for tp in range(5,X.shape[2]):\n",
    "        x = X[:,:,tp-5:tp+1]\n",
    "        x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': True, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "\n",
    "        if tp != X.shape[2]+4:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(5, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [True]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3. Cue-based direction (short)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2.1. Single timepoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'cue aligned 4 class direction (short)'\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BTT-s' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TTB-s' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RTL-s' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LTR-s' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2]\n",
    "    for tp in range(X.shape[2]):\n",
    "        x = X[:,:,tp]\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': False, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(0, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [False]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2.2. Windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 timestamps classifier:\n",
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying for subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BTT-s' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TTB-s' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RTL-s' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LTR-s' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2] - 5\n",
    "    for tp in range(5,X.shape[2]):\n",
    "        x = X[:,:,tp-5:tp+1]\n",
    "        x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': True, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "\n",
    "        if tp != X.shape[2]+4:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(5, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [True]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3. Cue-based direction (long)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.1. Single timepoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'cue aligned 4 class direction (long)'\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BTT-l' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TTB-l' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RTL-l' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LTR-l' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2]\n",
    "    for tp in range(X.shape[2]):\n",
    "        x = X[:,:,tp]\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': False, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(0, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [False]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.2. Windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 timestamps classifier:\n",
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying for subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BTT-l' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TTB-l' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RTL-l' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LTR-l' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2] - 5\n",
    "    for tp in range(5,X.shape[2]):\n",
    "        x = X[:,:,tp-5:tp+1]\n",
    "        x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': True, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "\n",
    "        if tp != X.shape[2]+4:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(5, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [True]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4. Movement-onset--based direction (all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mne.set_log_level('INFO')\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'movement onset aligned 2 class long v short'\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}', end=' ')\n",
    "    file_names = [f for f in listdir(path) if '_bad_annotations_raw.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    raw = load_raw_file(dirpath=path, file=file_names[0])\n",
    "\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Select subset of event_dict with following markers:\n",
    "\n",
    "    # Looking at indication release (movement onset):\n",
    "    trial_type = trial_type_markers\n",
    "    period = ['i'] # 'i', 'c' .. indication, cue\n",
    "    position = ['l', 'r', 't', 'b', 'c']\n",
    "    state = ['1'] # 0,1 .. touch/release\n",
    "    markers_of_interest = generate_markers_of_interest(trial_type, period, position, state)\n",
    "\n",
    "    event_dict_of_interest = get_subset_of_dict(event_dict, markers_of_interest)\n",
    "\n",
    "    epochs = mne.Epochs(raw, events_from_annot, event_id=event_dict_of_interest, tmin=-2.0, tmax=3.5, baseline=None, reject_by_annotation=True, preload=True, picks=['eeg'], reject=dict(eeg=200e-6 ))\n",
    "\n",
    "    # Downsample to 10 Hz:\n",
    "    epochs = epochs.copy().resample(10)\n",
    "\n",
    "    # Save epochs:\n",
    "    store_name = path + '/' + subject + '_' + paradigm + '_epo.fif'\n",
    "    epochs.save(store_name, overwrite=True)\n",
    "\n",
    "    print()\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.1. Single timepoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'movement onset aligned 4 class direction (all)'\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BT' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TT' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RT' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LT' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2]\n",
    "    for tp in range(X.shape[2]):\n",
    "        x = X[:,:,tp]\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': False, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(0, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [False]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.2. Windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 timestamps classifier:\n",
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying for subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BT' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TT' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RT' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LT' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2] - 5\n",
    "    for tp in range(5,X.shape[2]):\n",
    "        x = X[:,:,tp-5:tp+1]\n",
    "        x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': True, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "\n",
    "        if tp != X.shape[2]+4:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(5, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [True]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5. Movement-onset--based direction (short)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5.1. Single timepoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'movement onset aligned 4 class direction (short)'\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BTT-s' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TTB-s' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RTL-s' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LTR-s' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2]\n",
    "    for tp in range(X.shape[2]):\n",
    "        x = X[:,:,tp]\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': False, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(0, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [False]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5.2. Windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 timestamps classifier:\n",
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying for subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BTT-s' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TTB-s' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RTL-s' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LTR-s' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2] - 5\n",
    "    for tp in range(5,X.shape[2]):\n",
    "        x = X[:,:,tp-5:tp+1]\n",
    "        x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': True, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "\n",
    "        if tp != X.shape[2]+4:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(5, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [True]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.6. Movement-onset--based direction (long)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6.1. Single timepoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "# Set the epoch type\n",
    "epoch_type = 'movement onset aligned 4 class direction (long)'\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BTT-l' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TTB-l' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RTL-l' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LTR-l' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2]\n",
    "    for tp in range(X.shape[2]):\n",
    "        x = X[:,:,tp]\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': False, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "        if tp != X.shape[2]-1:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(0, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [False]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6.2. Windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 timestamps classifier:\n",
    "start = time.time()\n",
    "\n",
    "df_scores = create_scores_df()\n",
    "\n",
    "for subject, path in zip(subjects, paths):\n",
    "    print(f'Classifying for subject {subject}')\n",
    "    file_names = [f for f in listdir(path) if 'epo.fif' in f]\n",
    "\n",
    "    # Load file\n",
    "    file_name = file_names[0]\n",
    "    file = path + '/' + file_name\n",
    "    epochs = mne.read_epochs(file, preload=True)\n",
    "\n",
    "    # Get condition:\n",
    "    ups = [m for m in markers_of_interest if 'BTT-l' in m]\n",
    "    downs = [m for m in markers_of_interest if 'TTB-l' in m]\n",
    "    lefts = [m for m in markers_of_interest if 'RTL-l' in m]\n",
    "    rights = [m for m in markers_of_interest if 'LTR-l' in m]\n",
    "    epochs_up = epochs[ups]\n",
    "    epochs_down = epochs[downs]\n",
    "    epochs_right = epochs[rights]\n",
    "    epochs_left = epochs[lefts]\n",
    "\n",
    "    # Create data matrix X (epochs x channels x timepoints) and label vector y (epochs x 1):\n",
    "    X = np.concatenate([epochs_up.get_data(), epochs_down.get_data(), epochs_right.get_data(), epochs_left.get_data()])\n",
    "    y = np.concatenate([np.zeros(len(epochs_up)), np.ones(len(epochs_down)), 2*np.ones(len(epochs_right)), 3*np.ones(len(epochs_left))])\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    n_len = X.shape[2] - 5\n",
    "    for tp in range(5,X.shape[2]):\n",
    "        x = X[:,:,tp-5:tp+1]\n",
    "        x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "\n",
    "        scores = cross_val_score(clf, x, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "        # Add row to the dataframe:\n",
    "        row_to_add = {'Timepoint': tp/10 + epochs.tmin, 'Accuracy': scores.mean(), 'Subject': subject, '5-point': True, 'Type': epoch_type, 'Init_marker': [markers_of_interest], 't_min': epochs.tmin, 't_max': epochs.tmax, 'epoch_info': [epochs.info], 'Date':datetime.now().strftime('%Y-%m-%d'), 'Time': datetime.now().strftime('%H:%M:%S')}\n",
    "        df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "\n",
    "\n",
    "        if tp != X.shape[2]+4:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}', end='\\r')\n",
    "        else:\n",
    "            print(f'Measuring timestamp {tp+1}/{X.shape[2]}')\n",
    "\n",
    "# Add mean of scores as subject: Mean:\n",
    "# Add row to the dataframe:\n",
    "row_to_add = {'Timepoint': (np.arange(5, X.shape[2])/10).tolist() + epochs.tmin, 'Accuracy': df_scores.groupby('Timepoint')['Accuracy'].mean().to_list(), 'Subject': ['Mean']*n_len, '5-point': [True]*n_len, 'Type': [epoch_type]*n_len, 'Init_marker': [markers_of_interest]*n_len, 't_min': [epochs.tmin]*n_len, 't_max': [epochs.tmax]*n_len, 'epoch_info': [[epochs.info]]*n_len, 'Date':[datetime.now().strftime('%Y-%m-%d')]*n_len, 'Time': [datetime.now().strftime('%H:%M:%S')]*n_len}\n",
    "df_scores = pd.concat([df_scores, pd.DataFrame(row_to_add)], ignore_index=True)\n",
    "# Store dataframe to full classification dataframe:\n",
    "store_scores_df(df_scores)\n",
    "\n",
    "print(f'Finished classification, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('classification_df.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.line(df, x='Timepoint', y='Accuracy', color='Subject', facet_col='5-point', facet_row='Type')\n",
    "fig.show()\n",
    "fig.write_html('classification_accuracies.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}