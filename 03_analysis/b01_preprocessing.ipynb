{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mne\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import custom_modules.xdf_to_fif_converter as xtfc\n",
    "import custom_modules.preprocessing_ptu as prep\n",
    "import custom_modules.file_handling as  fh\n",
    "\n",
    "import importlib\n",
    "importlib.reload(xtfc)\n",
    "importlib.reload(prep)\n",
    "importlib.reload(fh)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mne.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = 'D:/Diplomarbeit_data/eeg/'\n",
    "subjects = ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07' , 'A08', 'A09', 'A10']\n",
    "trial_type_markers = ['LTR-s', 'LTR-l','RTL-s', 'RTL-l', 'TTB-s', 'TTB-l', 'BTT-s', 'BTT-l']\n",
    "\n",
    "mne.set_log_level('WARNING') #'INFO' 'WARNING'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. XDF --> FIF\n",
    "The following cell reads all xdf-files containing the raw eeg and loads them into the mne structure and stores them as .fif-files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(xtfc.xdf_to_fif)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='raw', dst_fldr='raw_fif')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Extracting subject {subject}', end=' ')\n",
    "\n",
    "    # Call the xdf_to_fif function from the xtfc module which takes care of converting the xdf files to fif files:\n",
    "    xtfc.xdf_to_fif(src_path, dst_path, subject)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f'Finished reading, took me {round(time.time()-start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Concatenate all fif files for each subject"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(prep.concat_fifs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='raw_fif', dst_fldr='concat')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Reading all fif files for subject {subject}', end=' ')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm and the eye paradigm:\n",
    "    prep.concat_fifs(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "    prep.concat_fifs(src=src_path, dst=dst_path, sbj=subject, paradigm='eye')\n",
    "    print()\n",
    "\n",
    "print(f'Finished concatenating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Filter  the data (HP 0.4 Hz and Notch 50 Hz)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(prep.filter_fifs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='concat', dst_fldr='filtered')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Filtering raw EEG for subject {subject}')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm and the eye paradigm:\n",
    "    prep.filter_fifs(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "    prep.filter_fifs(src=src_path, dst=dst_path, sbj=subject, paradigm='eye')\n",
    "\n",
    "print(f'Finished filtering, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Interpolate bad channels\n",
    "\n",
    "In this cell the bad channels are interpolated based on visual inspection. The visual inspection was performed prior and the channels are stored in ***/dataframes/preprocessing/bad_channels.csv***"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(prep.interpolate_bads)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='filtered', dst_fldr='bad_ch_interpolated')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Interpolating bad channels for subject {subject}')\n",
    "\n",
    "    # Interpolate bad channels for all raw files for the paradigm and the eye paradigm:\n",
    "    prep.interpolate_bads(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "    prep.interpolate_bads(src=src_path, dst=dst_path, sbj=subject, paradigm='eye')\n",
    "\n",
    "print(f'Finished interpolating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. CAR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='bad_ch_interpolated', dst_fldr='car_filtered')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Re-referencing for subject {subject}')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm:\n",
    "    prep.car(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "\n",
    "print(f'Finished interpolating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Mark bad dataspans\n",
    "Mark bad dataspans due to user errors in paradigm."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='car_filtered', dst_fldr='bad_dataspans_marked')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Marking bad dataspans for outlier detection for subject {subject}')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm:\n",
    "    prep.mark_bad_dataspans(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "\n",
    "print(f'Finished interpolating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. Epoching for outlier detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='bad_dataspans_marked', dst_fldr='epoched_for_outlier_detection')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Epoching for outlier detection for subject {subject}')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm:\n",
    "    prep.epoch_for_outlier_detection(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "\n",
    "print(f'Finished interpolating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.1. Visualize epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='epoched_movement_aligned', dst_fldr='epoched_for_outlier_detection')\n",
    "\n",
    "sbj_to_vis = 'A01'\n",
    "\n",
    "# Visualize epochs for subject:\n",
    "epochs = prep.vis_epochs_for_sbj(src=src_path, sbj=sbj_to_vis)\n",
    "fig = epochs[9].plot(picks=['eeg', 'eog'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 10. Lowpass filtering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='bad_dataspans_marked', dst_fldr='lowpass_filtered')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Lowpass filter for subject {subject}')\n",
    "\n",
    "    # Lowpass filter all raw files for the paradigm:\n",
    "    prep.lowpass_filter(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "\n",
    "print(f'Finished lowpass filtering, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 11. Epoch and resample:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11.1. Cue-aligned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='lowpass_filtered', dst_fldr='epoched_cue_aligned')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Epoching cue-aligned for subject {subject}')\n",
    "\n",
    "    # Epoch all raw files for the paradigm:\n",
    "    prep.epoch_and_resample(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm', cue_aligned=True)\n",
    "\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11.2. Movement-onset aligned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='lowpass_filtered', dst_fldr='epoched_movement_aligned')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Epoching movement-aligned for subject {subject}')\n",
    "\n",
    "    # Epoch all raw files for the paradigm:\n",
    "    prep.epoch_and_resample(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm', cue_aligned=False)\n",
    "\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 12. Epoch for plotting (without downsampling):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 12.1. Cue-aligned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='lowpass_filtered', dst_fldr='epoched_cue_aligned_not_resampled')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Epoching cue-aligned for subject {subject}')\n",
    "\n",
    "    # Epoch all raw files for the paradigm:\n",
    "    prep.epoch_and_resample(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm', cue_aligned=True, resample=False)\n",
    "\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keep this line while editing in preprocessing:\n",
    "importlib.reload(prep)\n",
    "\n",
    "# Plot cue-aligned grand average:\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='epoched_cue_aligned_not_resampled', dst_fldr='results_epoched_cue_aligned')\n",
    "\n",
    "prep.plot_grand_average(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=[''])\n",
    "\n",
    "prep.plot_grand_average(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['long', 'short'])\n",
    "\n",
    "prep.plot_grand_average(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['up', 'down', 'left', 'right'])\n",
    "\n",
    "times_of_interest = [0.9, 1.5, 2.0, 2.1, 2.2, 2.3]\n",
    "\n",
    "# prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=[''], times=times_of_interest)\n",
    "#\n",
    "# prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['long', 'short'], times=times_of_interest)\n",
    "#\n",
    "# prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['up', 'down', 'left', 'right'], times=times_of_interest)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keep this line while editing in preprocessing:\n",
    "importlib.reload(prep)\n",
    "\n",
    "# Plot cue-aligned grand average:\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='epoched_cue_aligned_not_resampled', dst_fldr='results_epoched_cue_aligned_after_coeff_testing')\n",
    "\n",
    "# Based on coefficient testing topoplot at 3.1s\n",
    "times_of_interest = list(np.arange(2.0,3.4,0.1))\n",
    "\n",
    "prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=[''], times=times_of_interest, ncols=7)\n",
    "\n",
    "prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['long', 'short'], times=times_of_interest, ncols=7)\n",
    "\n",
    "prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['up', 'down', 'left', 'right'], times=times_of_interest, ncols=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keep this line while editing in preprocessing:\n",
    "importlib.reload(prep)\n",
    "\n",
    "# Plot cue-aligned grand average:\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='epoched_cue_aligned_not_resampled', dst_fldr='results_epoched_cue_aligned')\n",
    "\n",
    "# Based on coefficient testing topoplot at 3.1s\n",
    "times_of_interest = list(np.arange(2.0,3.4,0.1))\n",
    "\n",
    "prep.plot_grand_average(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=[''], plot_topo=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 12.1. Movement-aligned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='lowpass_filtered', dst_fldr='epoched_movement_aligned_not_resampled')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Epoching movement-aligned for subject {subject}')\n",
    "\n",
    "    # Epoch all raw files for the paradigm:\n",
    "    prep.epoch_and_resample(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm', cue_aligned=False, resample=False)\n",
    "\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot movement-aligned grand average:\n",
    "# Keep this line while editing in preprocessing:\n",
    "importlib.reload(prep)\n",
    "\n",
    "# Plot cue-aligned grand average:\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='epoched_movement_aligned_not_resampled', dst_fldr='results_epoched_movement_aligned')\n",
    "\n",
    "epochs = prep.plot_grand_average(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=[''])\n",
    "\n",
    "prep.plot_grand_average(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['long', 'short'])\n",
    "\n",
    "prep.plot_grand_average(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['up', 'down', 'left', 'right'])\n",
    "\n",
    "times_of_interest = [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "times_of_interest = list(np.arange(-0.4,1.0,0.1))\n",
    "\n",
    "# prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=[''], times=times_of_interest)\n",
    "\n",
    "# prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['long', 'short'], times=times_of_interest)\n",
    "\n",
    "# prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['up', 'down', 'left', 'right'], times=times_of_interest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keep this line while editing in preprocessing:\n",
    "importlib.reload(prep)\n",
    "\n",
    "# Plot cue-aligned grand average:\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='epoched_movement_aligned_not_resampled', dst_fldr='results_epoched_movement_aligned_after_coeff_testing')\n",
    "\n",
    "# Based on coefficient testing topoplot at 3.1s\n",
    "times_of_interest = [0.0, 1.3]\n",
    "times_of_interest = list(np.arange(-0.4,1.0,0.1))\n",
    "\n",
    "prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=[''], times=times_of_interest, ncols=7)\n",
    "\n",
    "prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['long', 'short'], times=times_of_interest, ncols=7)\n",
    "\n",
    "prep.plot_topomaps(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=['up', 'down', 'left', 'right'], times=times_of_interest, ncols=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot movement-aligned grand average:\n",
    "# Keep this line while editing in preprocessing:\n",
    "importlib.reload(prep)\n",
    "\n",
    "# Plot cue-aligned grand average:\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='epoched_movement_aligned_not_resampled', dst_fldr='results_epoched_movement_aligned')\n",
    "\n",
    "epochs = prep.plot_grand_average(src=src_path, dst=dst_path, sbj_list=subjects, paradigm='paradigm', split=[''], plot_topo=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get difference between cue onset and movement onset (*i*1):\n",
    "trial_type_markers = ['LTR-s', 'LTR-l', 'RTL-s', 'RTL-l', 'TTB-s', 'TTB-l', 'BTT-s', 'BTT-l']\n",
    "cue_times = []\n",
    "release_times = []\n",
    "touch_times = []\n",
    "for i, entry in enumerate(epochs.annotations.description):\n",
    "    if entry in trial_type_markers:\n",
    "        if 'bad' in epochs.annotations.description[i+1]:\n",
    "            continue\n",
    "        else:\n",
    "            # Get delay between cue which is 'Cue' at i+3 and ix1 at i+4 and cx0 at i+5\n",
    "            cue_times.append(epochs.annotations.onset[i+3])\n",
    "            release_times.append(epochs.annotations.onset[i+4])\n",
    "            touch_times.append(epochs.annotations.onset[i+5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "diff_cue_release = np.array(release_times) - np.array(cue_times)\n",
    "diff_release_touch = np.array(touch_times) - np.array(release_times)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bins=np.arange(epochs.tmin, epochs.tmax, 1/epochs.info['sfreq'])\n",
    "hist = np.histogram(diff_cue_release, bins=bins, range=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kernel = gauss(n=55, b=0.04*epochs.info['sfreq'])\n",
    "\n",
    "smoothed = np.convolve(hist[0], kernel, 'same')\n",
    "x = np.arange(epochs.tmin, epochs.tmax+1/epochs.info['sfreq'], 1/epochs.info['sfreq'])\n",
    "plt.plot(smoothed)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gauss(n=11,b=0.04):\n",
    "    r = range(-int(n/2),int(n/2)+1)\n",
    "    return [np.exp(-float(x)**2/(2*b**2)) for x in r]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(smoothed)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs.tmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trial_type_markers = ['LTR-s', 'LTR-l', 'RTL-s', 'RTL-l', 'TTB-s', 'TTB-l', 'BTT-s', 'BTT-l']\n",
    "for i, entry in enumerate(descriptions):\n",
    "    if entry in trial_type_markers:\n",
    "        if 'bad' in descriptions[i+1]:\n",
    "            continue\n",
    "        else:\n",
    "            trial_type = entry\n",
    "            period = 'i'  # indication\n",
    "            position = descriptions[i+2][2]\n",
    "            state = descriptions[i+2][4]\n",
    "\n",
    "            descriptions[i+2] = trial_type + '_' + period + position + state\n",
    "\n",
    "            trial_type = entry\n",
    "            period = 'i'  # indication\n",
    "            position = descriptions[i+4][2]\n",
    "            state = descriptions[i+4][4]\n",
    "\n",
    "            descriptions[i+4] = trial_type + '_' + period + position + state\n",
    "\n",
    "            trial_type = entry\n",
    "            period = 'c'  # cue\n",
    "            position = descriptions[i+5][2]\n",
    "            state = descriptions[i+5][4]\n",
    "\n",
    "            descriptions[i+5] = trial_type + '_' + period + position + state\n",
    "\n",
    "            trial_type = entry\n",
    "            period = 'c'  # cue\n",
    "            position = descriptions[i+7][2]\n",
    "            state = descriptions[i+7][4]\n",
    "\n",
    "            descriptions[i+7] = trial_type + '_' + period + position + state\n",
    "\n",
    "return descriptions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}