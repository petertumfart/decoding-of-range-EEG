{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'custom_modules.file_handling' from 'C:\\\\Users\\\\peter\\\\Documents\\\\Code\\\\master-thesis\\\\03_analysis\\\\custom_modules\\\\file_handling.py'>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import time\n",
    "import os\n",
    "import custom_modules.xdf_to_fif_converter as xtfc\n",
    "import custom_modules.preprocessing_ptu as prep\n",
    "import custom_modules.file_handling as  fh\n",
    "\n",
    "import importlib\n",
    "importlib.reload(xtfc)\n",
    "importlib.reload(prep)\n",
    "importlib.reload(fh)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_path = 'D:/Diplomarbeit_data/eeg/'\n",
    "subjects = ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07' , 'A08', 'A09', 'A10']\n",
    "trial_type_markers = ['LTR-s', 'LTR-l','RTL-s', 'RTL-l', 'TTB-s', 'TTB-l', 'BTT-s', 'BTT-l']\n",
    "\n",
    "mne.set_log_level('WARNING') #'INFO' 'WARNING'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. XDF --> FIF\n",
    "The following cell reads all xdf-files containing the raw eeg and loads them into the mne structure and stores them as .fif-files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(xtfc.xdf_to_fif)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='raw', dst_fldr='raw_fif')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Extracting subject {subject}', end=' ')\n",
    "\n",
    "    # Call the xdf_to_fif function from the xtfc module which takes care of converting the xdf files to fif files:\n",
    "    xtfc.xdf_to_fif(src_path, dst_path, subject)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f'Finished reading, took me {round(time.time()-start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Concatenate all fif files for each subject"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(prep.concat_fifs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='raw_fif', dst_fldr='concat')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Reading all fif files for subject {subject}', end=' ')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm and the eye paradigm:\n",
    "    prep.concat_fifs(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "    prep.concat_fifs(src=src_path, dst=dst_path, sbj=subject, paradigm='eye')\n",
    "    print()\n",
    "\n",
    "print(f'Finished concatenating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Filter  the data (HP 0.4 Hz and Notch 50 Hz)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(prep.filter_fifs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='concat', dst_fldr='filtered')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Filtering raw EEG for subject {subject}')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm and the eye paradigm:\n",
    "    prep.filter_fifs(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "    prep.filter_fifs(src=src_path, dst=dst_path, sbj=subject, paradigm='eye')\n",
    "\n",
    "print(f'Finished filtering, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Interpolate bad channels\n",
    "\n",
    "In this cell the bad channels are interpolated based on visual inspection. The visual inspection was performed prior and the channels are stored in ***/dataframes/preprocessing/bad_channels.csv***"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(prep.interpolate_bads)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='filtered', dst_fldr='bad_ch_interpolated')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Interpolating bad channels for subject {subject}')\n",
    "\n",
    "    # Interpolate bad channels for all raw files for the paradigm and the eye paradigm:\n",
    "    prep.interpolate_bads(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "    prep.interpolate_bads(src=src_path, dst=dst_path, sbj=subject, paradigm='eye')\n",
    "\n",
    "print(f'Finished interpolating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. CAR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='bad_ch_interpolated', dst_fldr='car_filtered')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Re-referencing for subject {subject}')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm:\n",
    "    prep.car(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "\n",
    "print(f'Finished interpolating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Mark bad dataspans\n",
    "Mark bad dataspans due to user errors in paradigm."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='car_filtered', dst_fldr='bad_dataspans_marked')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Marking bad dataspans for outlier detection for subject {subject}')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm:\n",
    "    prep.mark_bad_dataspans(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "\n",
    "print(f'Finished interpolating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. Epoching for outlier detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='bad_dataspans_marked', dst_fldr='epoched_for_outlier_detection')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Epoching for outlier detection for subject {subject}')\n",
    "\n",
    "    # Concatenate all raw files for the paradigm:\n",
    "    prep.epoch_for_outlier_detection(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "\n",
    "print(f'Finished interpolating, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.1. Visualize epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='epoched_movement_aligned', dst_fldr='epoched_for_outlier_detection')\n",
    "\n",
    "sbj_to_vis = 'A01'\n",
    "\n",
    "# Visualize epochs for subject:\n",
    "epochs = prep.vis_epochs_for_sbj(src=src_path, sbj=sbj_to_vis)\n",
    "fig = epochs[9].plot(picks=['eeg', 'eog'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 10. Lowpass filtering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='bad_dataspans_marked', dst_fldr='lowpass_filtered')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Lowpass filter for subject {subject}')\n",
    "\n",
    "    # Lowpass filter all raw files for the paradigm:\n",
    "    prep.lowpass_filter(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm')\n",
    "\n",
    "print(f'Finished lowpass filtering, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 11. Epoch and resample:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11.1. Cue-aligned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='lowpass_filtered', dst_fldr='epoched_cue_aligned')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Epoching cue-aligned for subject {subject}')\n",
    "\n",
    "    # Epoch all raw files for the paradigm:\n",
    "    prep.epoch_and_resample(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm', cue_aligned=True)\n",
    "\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11.2. Movement-onset aligned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get source and destination path + create destintation folder if it does not exist.\n",
    "src_path, dst_path = fh.gen_paths(pth=data_path, src_fldr='lowpass_filtered', dst_fldr='epoched_movement_aligned')\n",
    "\n",
    "# Iterate over each subject and extract the streams\n",
    "start = time.time()\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(f'Epoching movement-aligned for subject {subject}')\n",
    "\n",
    "    # Epoch all raw files for the paradigm:\n",
    "    prep.epoch_and_resample(src=src_path, dst=dst_path, sbj=subject, paradigm='paradigm', cue_aligned=False)\n",
    "\n",
    "print(f'Finished epoching, took me {round(time.time() - start)} seconds...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}